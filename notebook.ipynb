{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T10:25:25.065259Z",
     "start_time": "2024-01-10T10:25:21.443668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content='Victory Mansions is a dilapidated and run-down residential building located in London, specifically in Airstrip One, which is the third most populous province of Oceania. The building is described as having crumbling walls and broken elevators. The hallways are dimly lit and filled with the smell of boiled cabbage. It is constantly under surveillance by telescreens, which are large television screens that transmit propaganda and monitor the residents. The atmosphere is oppressive, with a sense of constant surveillance and control. The building has glass doors and a hallway that smells of boiled cabbage and old rag mats. There is a large colored poster on one end of the hallway, depicting the face of a man in his forties with a black mustache and ruggedly handsome features. The flat in which Winston Smith resides is located on the seventh floor, and the building has a non-functioning lift due to the electricity being cut off during daylight hours. On each landing, there is a poster with the face of Big Brother, with the caption \"BIG BROTHER IS WATCHING YOU.\" The overall appearance of Victory Mansions is rundown and neglected, with a grimy landscape of rotting nineteenth-century houses surrounding it.')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "# RunnableLambda : chain과 그 내부 어디에서든 function을 호출할 수 있도록 함\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator='\\n',\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.docx\")\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# cache_dir에 있는 embed를 확인하고 업으면 OpenAIEmbeddings 사용\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "\n",
    "# list of docs -> Victory Mansions을 묘사하는 것과 관련된 document list를 retriever가 반환\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        Use the following portion of a long document to see if any of the text is relevant to answer the question. Return any relevant text verbatim.\n",
    "        -------\n",
    "        {context}\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "\n",
    "def map_docs(inputs) -> str:\n",
    "    \"\"\"\n",
    "    :param inputs: [{\"documents\": List[Document], \"question\": str}]\n",
    "    :return: final chain의 context가 될 부분. str\n",
    "    \"\"\"\n",
    "\n",
    "    documents = inputs['documents']\n",
    "    question = inputs['question']\n",
    "\n",
    "    # for doc in list of docs | promt | llm -> 모든 document에 대한 prompt를 만들어서 llm에 전달. 질문: \"이 doc을 읽고 question에 답하는 데에 관련이 있는 중요한 정보를 추출해줘\"\n",
    "    # for response in list of llms response | put them all together -> response를 합해서 하나의 긴 document(final doc)\n",
    "    results = \"\\n\\n\".join(\n",
    "        map_doc_chain.invoke(\n",
    "            {\n",
    "                \"context\": doc.page_content,\n",
    "                \"question\": question\n",
    "            }\n",
    "        ).content\n",
    "        for doc in documents\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# document가 필요 -> retriever를 사용해서 얻을 수 있음\n",
    "# question이 필요. 그래야 llm에 요청할 수 있기 때문\n",
    "map_chain = {\n",
    "    \"documents\": retriever,\n",
    "    \"question\": RunnablePassthrough()\n",
    "} | RunnableLambda(map_docs)\n",
    "\n",
    "\n",
    "# final doc | prompt | llm -> final doc이 prompt에 입력되어 전달 + llm이 질문에 대답\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Given the following extracted part of a long document and a question, create a final answer.\n",
    "    If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "    ------\n",
    "    {context}\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# invoke가 실행될 때, map_chain이 context로 들어감\n",
    "chain = {\"context\": map_chain, \"question\": RunnablePassthrough()} | final_prompt | llm\n",
    "\n",
    "chain.invoke(\"Describe Victory Mansions.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
